<?php

return [
    [
        'id' => 1,
        'parentid' => 0,
        'name' => 'Robots.txt',
        'descr' => 'Файл Robots.txt – это обычный текстовый файл в формате .txt, содержащий инструкции и директивы для поисковых роботов, запрещающие индексировать определенные файлы сайта, его документы и папки. То есть, данный файл ограничивает ботам поисковых систем доступ к содержимому сайта.'
    ],

    [
        'id' => 2,
        'parentid' => 0,
        'name' => 'Sitemap.xml',
        'descr' => ''
    ],
    
    [
        'id' => 3,
        'parentid' => 0,
        'name' => '301 редирект',
        'descr' => ''
    ],
    
    [
        'id' => 4,
        'parentid' => 0,
        'name' => '404 страница',
        'descr' => ''
    ],
    
    [
        'id' => 5,
        'parentid' => 0,
        'name' => 'HTTP/HTTPS',
        'descr' => ''
    ],
    
    [
        'id' => 6,
        'parentid' => 0,
        'name' => 'Человеко Понятный Урл(ЧПУ)',
        'descr' => ''
    ],
    
    [
        'id' => 7,
        'parentid' => 1,
        'name' => 'Закрыты служебные и ненужные разделы',
        'descr' => ''
    ],
    
    [
        'id' => 8,
        'parentid' => 1,
        'name' => 'Закрыты страницы с динамическими параметрами',
        'descr' => ''
    ],
    
    [
        'id' => 9,
        'parentid' => 1,
        'name' => 'Заданы разные User-Agent для Яндекса и других роботов',
        'descr' => ''
    ]
];